---
group: "About Project"
icon: pi-cloud
---

# Live Demo Deployment

This page describes the deployment setup behind the live demo at **[sungyongcho.com/gomoku](https://sungyongcho.com/gomoku)** (including this docs site).

## Infrastructure

| Service | GCP Machine | vCPU | RAM |
|---------|------------|------|-----|
| Minimax | `e2-small` | 0.5–2 | 2 GB |
| AlphaZero | `c2d-standard-4` | 4 | 16 GB |

Both backends run as Docker containers on GCP Container-Optimized OS VMs. A Cloudflare Worker handles path-based routing (`/minimax/*`, `/alphazero/*`) to the respective backends.

The initial plan assumed a single-GPU setup, with most throughput gains expected from parallel CPU workers/actors.
Cluster design was intentionally kept simple early on, since deep infrastructure tuning would have delayed the core goal of training and model validation.
Worker/actor distribution still required iterative tuning to find stable speedups, but this approach kept infrastructure effort bounded while delivering model results faster.

For full deployment engineering details (Cloudflare Worker path routing, COS startup scripts, Artifact Registry image flow, and deployment scripts), see [AlphaZero Deployment](/docs/alphazero/deployment).

Response times on the live demo will vary from benchmark numbers cited in the documentation — the minimax engine in particular runs on a shared-core instance to keep hosting costs low.
